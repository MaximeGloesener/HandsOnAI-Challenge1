{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximeGloesener/HandsOnAI-Challenge1/blob/master/Challenge1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK6fZUXolwPs"
      },
      "source": [
        "# **1. Hardware Informations (GPU)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UEjh8Rulquq",
        "outputId": "78b4d52b-d696-414f-c759-eccd64fcd661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  9 12:43:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    30W /  70W |   8050MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtS3fRhb5x6"
      },
      "source": [
        "# **2. Import des librairies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS3XuLGyb5x_",
        "outputId": "a557904f-6094-47ff-8623-19d2c6f02c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.9.2\n",
            "Keras version: 2.9.0\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Connexion au drive**"
      ],
      "metadata": {
        "id": "uwrkHPg6Zgkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "20yodqvHZF1i",
        "outputId": "4fd73dd4-9395-47b1-fd87-9029dd707caf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-BpaZnLDmn"
      },
      "source": [
        "#**4. Cretate the labels file \"classes.txt\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "70eR5xy2nNZP"
      },
      "outputs": [],
      "source": [
        "!printf '%s\\n' 'fire' 'no_fire' 'start_fire'> classes.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyXXoZphLN1-"
      },
      "source": [
        "#**5. Training parameters and selectioon of Pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3cIzhz5iNn7F"
      },
      "outputs": [],
      "source": [
        "# Fix random seed \n",
        "tf.keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HwKf5hQLnUPi"
      },
      "outputs": [],
      "source": [
        "nb_classes = 3\n",
        "nbr_batch_size=8 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
        "dataset_path = \"/content/gdrive/MyDrive/Challenge1/\"\n",
        "input_dim=224 #@param [224,299] {type:\"raw\"}  \n",
        "dataset_name=dataset_path+'big' \n",
        "\n",
        "dataset_path = os.path.join(dataset_name)\n",
        "classes_path = \"classes.txt\"\n",
        "csv_path = 'result.csv'\n",
        "epochs = 50 #@ param {type:\"slider\", min:5, max:100, step:5}\n",
        "\n",
        "result_path='results/'\n",
        "log_path='logs'\n",
        "\n",
        "classifier = \"Xception\"\n",
        "result_path = 'results/'+classifier\n",
        "log={\n",
        "    'epochs':epochs,\n",
        "    'batch_size':nbr_batch_size,\n",
        "    'val_loss':-1,\n",
        "    'val_acc':-1,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SBzh646b5yz"
      },
      "source": [
        "# **6. Get the number of classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NZ55HVhkb5y3"
      },
      "outputs": [],
      "source": [
        "# Get the class names\n",
        "with open(classes_path, 'r') as f:\n",
        "    classes = f.readlines()\n",
        "    classes = list(map(lambda x: x.strip(), classes))\n",
        "num_classes = len(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTyWV0pQb5zD"
      },
      "source": [
        "# **8. Selection and configuration of the training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoWLjGra8Ls9",
        "outputId": "479b7c4b-e93c-4511-8432-ca262d0b81e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6060 files belonging to 3 classes.\n",
            "Using 4848 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdataset_path,                     # Path of the dataset\n",
        "\tvalidation_split=0.2,             # Data division : validation (20%), train (80%)\n",
        "\tsubset=\"training\",                # Selection of training data\n",
        "\tseed=42,                          # Initialization of random generator (for permutations)\n",
        "\timage_size=(224,224),    # Input size of images\n",
        "\tbatch_size=nbr_batch_size,        # Batch_size\n",
        "  label_mode=\"categorical\"     # Conversion to One-Hot format\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji2AfPd88PC-"
      },
      "source": [
        "#**9. Selection and configuration of the validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Oruux4rRyDv",
        "outputId": "816fc4ee-0132-4cd0-b694-1e8635d370b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6060 files belonging to 3 classes.\n",
            "Using 1212 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdataset_path,                     # Path of the dataset\n",
        "\tvalidation_split=0.2,             # Data division : validation (20%), train (80%)\n",
        "\tsubset=\"validation\",                # Selection of validation data\n",
        "\tseed=42,                          # Initialization of random generator (for permutations)\n",
        "\timage_size=(224,224),    # Input size of images\n",
        "\tbatch_size=nbr_batch_size,        # Batch_size\n",
        "  label_mode=\"categorical\"     # Conversion to One-Hot format\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi8oBrIJWa5s"
      },
      "source": [
        "# **10. Download the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WCBo9Oyb5zc",
        "outputId": "ff2cb093-5ad3-4bc8-cc86-f5cd6abfc5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = Xception(include_top = False, weights ='imagenet',input_shape = (input_dim,input_dim,3))\n",
        "model = base_model.output\n",
        "model = Flatten()(model)\n",
        "model = Dense(128,activation='relu')(model)\n",
        "model = Dropout(0.8)(model)\n",
        "model = Dense(64,activation = 'relu')(model)\n",
        "model = Dropout(0.4)(model)\n",
        "predictions = Dense(num_classes, activation = 'softmax')(model)\n",
        "model = Model(inputs=base_model.inputs, outputs=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CWnXEPb5zX"
      },
      "source": [
        "# **13. Model training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPGAZ2Vab5zo"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# pour permettre le ré-entrainement des couches\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# recompiler le modèle\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001,decay=1e-6)\n",
        "opt2 = keras.optimizers.Adam(lr=0.0001)\n",
        "opt3 = keras.optimizers.RMSprop(learning_rate = 0.0001,decay =1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt3,metrics=['accuracy'])  \n",
        "\n",
        "\n",
        "# Création du dossier pour sauvegrader le model\n",
        "if os.path.exists(result_path) == False:\n",
        "    os.makedirs(result_path)\n",
        "\n",
        "\n",
        "keras_callback = [EarlyStopping(monitor='val_loss',patience = 10, verbose = 2)]\n",
        "\n",
        "history=model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=math.ceil(len(train_ds)),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=math.ceil(len(val_ds)),\n",
        "    verbose=1,\n",
        "    callbacks = keras_callback\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVOg-VgI9YMB"
      },
      "source": [
        "#**14. Save your model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbAlAYpm9fg5"
      },
      "outputs": [],
      "source": [
        "model.save('xception2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_ljTXlMSIZ"
      },
      "source": [
        "#**15. Visualization of training/validation curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtIwdjee_KLk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvX9QXRCh1GJ",
        "outputId": "a827ec6e-2638-4cd2-825d-b33c8fa99c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 210 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "testdata_path = \"/content/gdrive/MyDrive/Challenge1/test_data/test/Test_Dataset\"\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\ttestdata_path,          # chemin vers le jeu de données\n",
        "\tseed=42,                    # Initialisation du générateur aléatoire (permutations)\n",
        "\timage_size=(input_dim,input_dim),       # Taille des images d'entrée\n",
        "\tbatch_size=nbr_batch_size,      # Taille du mini-batch\n",
        "  label_mode='categorical'    # Conversion au format One-Hot\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/gdrive/MyDrive/Challenge1/NGGYU_model.h5')"
      ],
      "metadata": {
        "id": "39FxUXxBcLxv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxHxT0GFiQK4",
        "outputId": "d5eb613f-dd36-4d11-eb8e-d1cdda0d310c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 45s 2s/step - loss: 1.0557 - accuracy: 0.9667\n",
            "loss: 1.06%\n",
            "accuracy: 96.67%\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(test_ds,  steps=len(test_ds),workers = 1)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]))\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oECfYKSp_MaQ"
      },
      "source": [
        "#**16. Test the model with a test image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcKZUDoWUq0P"
      },
      "outputs": [],
      "source": [
        "filename = \"https://www.ecologie.gouv.fr/sites/default/files/styles/standard/public/Feux.png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_JRsQoh_chG"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "classes = train_ds.class_names\n",
        "image_path =  \"fog.jpg\"\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "x = tf.keras.utils.img_to_array(img,data_format='channels_last')\n",
        "x = tf.keras.preprocessing.image.smart_resize(x, size=(input_dim,input_dim))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# predict\n",
        "pred = model.predict(x,batch_size=1)[0]\n",
        "\n",
        "for (pos,prob) in enumerate(pred):\n",
        "    class_name = classes[pos]\n",
        "    if (pos == np.argmax(pred)) :\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX \n",
        "        textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
        "        textX = (img.shape[1] - textsize[0]) / 2\n",
        "        textY = (img.shape[0] + textsize[1]) / 2\n",
        "        cv2.putText(img, class_name, (int(textX)-10, int(textY)), font, 2, (255,0,0), 6, cv2.LINE_AA)\n",
        "        plt.imshow(img)\n",
        "    print(\"Class Name : %s\" % (class_name), \"---\", \"Class Probability: %.2f%%\" % (prob*100))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "28c92afe8325fc0816b2f334f44f38e4b06e562e4c3a673584693ef65fd7d28f"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}