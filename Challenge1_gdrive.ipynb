{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximeGloesener/HandsOnAI-Challenge1/blob/master/Challenge1_gdrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK6fZUXolwPs"
      },
      "source": [
        "# **1. Hardware Informations (GPU)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UEjh8Rulquq",
        "outputId": "bd1613e7-8148-4034-dcb5-fd476037bb6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct 27 18:39:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqK0POsY1lmH",
        "outputId": "dbdee032-27a5-4032-9cd5-163d22f8c79d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ImageHash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from ImageHash) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from ImageHash) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ImageHash) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ImageHash) (1.7.3)\n",
            "Installing collected packages: ImageHash\n",
            "Successfully installed ImageHash-4.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ImageHash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtS3fRhb5x6"
      },
      "source": [
        "# **2. Importation of librairies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS3XuLGyb5x_",
        "outputId": "0ca87892-5651-4bca-a166-c7d2d39f30fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.9.2\n",
            "Keras version: 2.9.0\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "import imagehash\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6HqNeyYKraU"
      },
      "source": [
        "#**3. Download of training datasets \"FIRE_DATABASE_X\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1CwAmMbqmGhW"
      },
      "outputs": [],
      "source": [
        "bases_path_after=\"bases\"\n",
        "test=\"test_data\"\n",
        "if os.path.exists(bases_path_after) == False:\n",
        "    os.makedirs(bases_path_after)\n",
        "if not os.path.exists(test):\n",
        "  os.makedirs(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us_JlUVUXamR",
        "outputId": "d7cd78bf-e4bd-49ed-9e99-2aa090fe8538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-27 18:39:13--  http://195.154.53.219/downloads/test.tar\n",
            "Connecting to 195.154.53.219:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58196480 (56M) [application/octet-stream]\n",
            "Saving to: ‘test.tar’\n",
            "\n",
            "test.tar            100%[===================>]  55.50M  15.6MB/s    in 3.6s    \n",
            "\n",
            "2022-10-27 18:39:17 (15.6 MB/s) - ‘test.tar’ saved [58196480/58196480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Données de test\n",
        "!rm -rf sample_data\n",
        "!wget --no-check-certificate http://195.154.53.219/downloads/test.tar\n",
        "! tar xf test.tar -C 'test_data' --one-top-level\n",
        "! rm test.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prGdb9QW88gL"
      },
      "source": [
        "Important de tester les doublons en utilisant un hash cryptographique qui comparer les images pixels par pixels. Avec un hash robuste, on trouve des faux doublons. Le hash robuste permet de détecter les doublons si resize/légère modifiction mais ce n'est pas le cas ici dans les datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIpQq5lygtsq",
        "outputId": "cb6c3230-5ac4-48c5-a088-a4659b46b557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Challenge1/all_data/fire/images - 2022-05-04T104035.076.jpeg doublons de /content/gdrive/MyDrive/Challenge1/all_data/fire/00000026.jpg\n",
            "/content/gdrive/MyDrive/Challenge1/all_data/fire/images - 2022-05-04T104052.887.jpeg doublons de /content/gdrive/MyDrive/Challenge1/all_data/fire/00000191.jpg\n",
            "DATASET\n",
            "Il y a 2 doublons dans le dataset = 0.11841326228537595% des données\n"
          ]
        }
      ],
      "source": [
        "# Analyse des données\n",
        "# On sait que dans les datasets, il y a parfois plusieurs fois la même image\n",
        "# But : analyser chaque dataset et trouver le nombre d'images en doublons\n",
        "def analyse_dataset(folder_name, affichage = False):\n",
        "  \"\"\"\n",
        "  Fonction qui prend en entrée le directory d'un dataset et qui va chercher les images qui sont présentes plusieurs fois pour ce même dataset\n",
        "  Affichage = True si on veut plot les images qui sont en doubles et leur nom\n",
        "  Return: - le nombre de doublons dans un dataset\n",
        "          - le pourcentage de doublons\n",
        "  \"\"\"\n",
        "  img_hashes = dict()\n",
        "  total = 0\n",
        "  doublons = 0\n",
        "\n",
        "  for dir in os.listdir(folder_name):\n",
        "    for image in os.listdir(os.path.join(folder_name, dir)):\n",
        "      total += 1\n",
        "      image = os.path.join(os.getcwd(), folder_name, dir, image)\n",
        "      hash = imagehash.dhash(Image.open(image))\n",
        "      if hash in img_hashes:\n",
        "        doublons += 1\n",
        "        print(f'{image} doublons de {img_hashes[hash]}')\n",
        "        if affichage:\n",
        "          i = read_image(image) \n",
        "          x = read_image(img_hashes[hash])\n",
        "          plot([x,i],[image.split(\"/\")[-1], img_hashes[hash].split(\"/\")[-1]])\n",
        "      else:\n",
        "        img_hashes[hash] = image\n",
        "\n",
        "  return doublons, doublons/total*100\n",
        "\n",
        "d1, p1 = analyse_dataset(\"/content/gdrive/MyDrive/Challenge1/all_data/\")\n",
        "print('DATASET')\n",
        "print(f'Il y a {d1} doublons dans le dataset = {p1}% des données')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e0FpgawA8NHh"
      },
      "outputs": [],
      "source": [
        "# Créer un seul dataset à partir des 3 en ne prenant en compte que des images uniques (supprimer tous les doublons)\n",
        "def make_dataset(base_directory):\n",
        "  \"\"\"\n",
        "  Fonction qui va concaténer les 3 datasets de départ et créer un seul dataset sans doublons\n",
        "  Return les hashs des images déjà présentes dans le dataset -> utile lors de la phase data augmentation pour \n",
        "  ne pas rajouter des images qui sont déjà présentes dans la jeu de données \n",
        "  \"\"\"\n",
        "  !rm -rf all_data\n",
        "  directory = 'all_data'\n",
        "  directory_path = os.path.join(os.getcwd(), directory)\n",
        "  # créer un nouveau directory all_data s'il n'existe pas déjà\n",
        "  if not os.path.exists(directory_path):\n",
        "    os.mkdir(directory_path)\n",
        "    os.mkdir(os.path.join(directory_path, \"fire\"))\n",
        "    os.mkdir(os.path.join(directory_path, \"no_fire\"))\n",
        "    os.mkdir(os.path.join(directory_path, \"start_fire\"))\n",
        "\n",
        "  images_hash = set()\n",
        "  for dir in os.listdir(base_directory):\n",
        "    for dir2 in os.listdir(os.path.join(base_directory,dir)):\n",
        "      for img in os.listdir(os.path.join(base_directory,dir,dir2)):\n",
        "        path = os.path.join(os.getcwd(), base_directory, dir, dir2, img)\n",
        "        hash = imagehash.dhash(Image.open(path))\n",
        "        if hash not in images_hash:\n",
        "          images_hash.add(hash)\n",
        "          cv2.imwrite(os.path.join(directory_path, dir2, img), cv2.imread(path))\n",
        "  return images_hash \n",
        "hashes = make_dataset(\"bases\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXAc626acFRF",
        "outputId": "4d6d1a38-8038-451c-8c03-ec1797e4e2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#%cp -av \"/content/all_data/\" \"/content/gdrive/MyDrive/Challenge1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_vXyxSxo4PL",
        "outputId": "eb26da7b-fddd-480f-9304-a5128f56384f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "699\n",
            "493\n",
            "497\n",
            "1689\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir(\"gdrive/MyDrive/Challenge1/all_data/fire\")))\n",
        "print(len(os.listdir(\"gdrive/MyDrive/Challenge1/all_data/start_fire\")))\n",
        "print(len(os.listdir(\"gdrive/MyDrive/Challenge1/all_data/no_fire\")))\n",
        "print(len(os.listdir(\"gdrive/MyDrive/Challenge1/all_data/fire\"))+len(os.listdir(\"gdrive/MyDrive/Challenge1/all_data/start_fire\"))+len(os.listdir(\"gdrive/MyDrive/Challenge1/all_data/no_fire\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-BpaZnLDmn"
      },
      "source": [
        "#**4. Cretate the labels file \"classes.txt\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70eR5xy2nNZP"
      },
      "outputs": [],
      "source": [
        "!printf '%s\\n' 'fire' 'no_fire' 'start_fire'> classes.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyXXoZphLN1-"
      },
      "source": [
        "#**5. Training parameters and selectioon of Pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cIzhz5iNn7F"
      },
      "outputs": [],
      "source": [
        "# Fix random seed \n",
        "tf.keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwKf5hQLnUPi"
      },
      "outputs": [],
      "source": [
        "nb_classes = 3\n",
        "nbr_batch_size=8 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
        "dataset_path = \"gdrive/MyDrive/Challenge1\"\n",
        "input_dim=224 #@param [224,299] {type:\"raw\"}  \n",
        "dataset_name='all_data' #@param [\"all_data\"]\n",
        "\n",
        "dataset_path = os.path.join(dataset_path,dataset_name)\n",
        "classes_path = \"classes.txt\"\n",
        "csv_path = 'result.csv'\n",
        "epochs = 30 #@ param {type:\"slider\", min:5, max:100, step:5}\n",
        "\n",
        "result_path='results/'\n",
        "log_path='logs'\n",
        "\n",
        "classifier = \"Xception\" #@param [\"ResNet50\",\"VGG19\",\"Xception\",\"MobileNet\",\"DenseNet169\"] {type:\"string\"}\n",
        "result_path = 'results/'+classifier\n",
        "log={\n",
        "    'epochs':epochs,\n",
        "    'batch_size':nbr_batch_size,\n",
        "    'val_loss':-1,\n",
        "    'val_acc':-1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94acb9Z0lc3i"
      },
      "outputs": [],
      "source": [
        "print(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SBzh646b5yz"
      },
      "source": [
        "# **6. Get the number of classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ55HVhkb5y3"
      },
      "outputs": [],
      "source": [
        "# Get the class names\n",
        "with open(classes_path, 'r') as f:\n",
        "    classes = f.readlines()\n",
        "    classes = list(map(lambda x: x.strip(), classes))\n",
        "num_classes = len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SqSdQUDkL-F"
      },
      "outputs": [],
      "source": [
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTyWV0pQb5zD"
      },
      "source": [
        "# **8. Selection and configuration of the training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoWLjGra8Ls9"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdataset_path,                     # Path of the dataset\n",
        "\tvalidation_split=0.2,             # Data division : validation (20%), train (80%)\n",
        "\tsubset=\"training\",                # Selection of training data\n",
        "\tseed=42,                          # Initialization of random generator (for permutations)\n",
        "\timage_size=(224,224),    # Input size of images\n",
        "\tbatch_size=nbr_batch_size,        # Batch_size\n",
        "  label_mode=\"categorical\"     # Conversion to One-Hot format\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji2AfPd88PC-"
      },
      "source": [
        "#**9. Selection and configuration of the validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Oruux4rRyDv"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdataset_path,                     # Path of the dataset\n",
        "\tvalidation_split=0.2,             # Data division : validation (20%), train (80%)\n",
        "\tsubset=\"validation\",                # Selection of validation data\n",
        "\tseed=42,                          # Initialization of random generator (for permutations)\n",
        "\timage_size=(224,224),    # Input size of images\n",
        "\tbatch_size=nbr_batch_size,        # Batch_size\n",
        "  label_mode=\"categorical\"     # Conversion to One-Hot format\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi8oBrIJWa5s"
      },
      "source": [
        "# **10. Download the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WCBo9Oyb5zc"
      },
      "outputs": [],
      "source": [
        "base_model = Xception(include_top = False, weights ='imagenet',input_shape = (input_dim,input_dim,3))\n",
        "model = base_model.output\n",
        "model = Flatten()(model)\n",
        "model = Dense(128,activation='relu')(model)\n",
        "model = Dropout(0.8)(model)\n",
        "model = Dense(64,activation = 'relu')(model)\n",
        "model = Dropout(0.4)(model)\n",
        "predictions = Dense(num_classes, activation = 'softmax')(model)\n",
        "model = Model(inputs=base_model.inputs, outputs=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CWnXEPb5zX"
      },
      "source": [
        "# **13. Model training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPGAZ2Vab5zo"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# pour permettre le ré-entrainement des couches\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# recompiler le modèle\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001,decay=1e-6)\n",
        "opt2 = keras.optimizers.Adam(lr=0.0001)\n",
        "opt3 = keras.optimizers.RMSprop(learning_rate = 0.0001,decay =1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt3,metrics=['accuracy'])  \n",
        "\n",
        "\n",
        "# Création du dossier pour sauvegrader le model\n",
        "if os.path.exists(result_path) == False:\n",
        "    os.makedirs(result_path)\n",
        "\n",
        "\n",
        "keras_callback = [EarlyStopping(monitor='val_loss',patience = 5, verbose = 2)]\n",
        "\n",
        "history=model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=math.ceil(len(train_ds)),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=math.ceil(len(val_ds)),\n",
        "    verbose=1,\n",
        "    callbacks = keras_callback\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVOg-VgI9YMB"
      },
      "source": [
        "#**14. Save your model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbAlAYpm9fg5"
      },
      "outputs": [],
      "source": [
        "model.save('xception2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_ljTXlMSIZ"
      },
      "source": [
        "#**15. Visualization of training/validation curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtIwdjee_KLk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvX9QXRCh1GJ"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\t'test_data/test',          # chemin vers le jeu de données\n",
        "\tseed=42,                    # Initialisation du générateur aléatoire (permutations)\n",
        "\timage_size=(input_dim,input_dim),       # Taille des images d'entrée\n",
        "\tbatch_size=nbr_batch_size,      # Taille du mini-batch\n",
        "  label_mode='categorical'    # Conversion au format One-Hot\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxHxT0GFiQK4"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(test_ds,  steps=len(test_ds),workers = 1)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]))\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oECfYKSp_MaQ"
      },
      "source": [
        "#**16. Test the model with a test image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcKZUDoWUq0P"
      },
      "outputs": [],
      "source": [
        "filename = \"https://www.ecologie.gouv.fr/sites/default/files/styles/standard/public/Feux.png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_JRsQoh_chG"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "classes = train_ds.class_names\n",
        "image_path =  \"fog.jpg\"\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "x = tf.keras.utils.img_to_array(img,data_format='channels_last')\n",
        "x = tf.keras.preprocessing.image.smart_resize(x, size=(input_dim,input_dim))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# predict\n",
        "pred = model.predict(x,batch_size=1)[0]\n",
        "\n",
        "for (pos,prob) in enumerate(pred):\n",
        "    class_name = classes[pos]\n",
        "    if (pos == np.argmax(pred)) :\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX \n",
        "        textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
        "        textX = (img.shape[1] - textsize[0]) / 2\n",
        "        textY = (img.shape[0] + textsize[1]) / 2\n",
        "        cv2.putText(img, class_name, (int(textX)-10, int(textY)), font, 2, (255,0,0), 6, cv2.LINE_AA)\n",
        "        plt.imshow(img)\n",
        "    print(\"Class Name : %s\" % (class_name), \"---\", \"Class Probability: %.2f%%\" % (prob*100))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "28c92afe8325fc0816b2f334f44f38e4b06e562e4c3a673584693ef65fd7d28f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
