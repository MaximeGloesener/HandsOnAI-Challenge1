{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximeGloesener/HandsOnAI-Challenge1/blob/master/Challenge1_gdrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK6fZUXolwPs"
      },
      "source": [
        "# **1. Hardware Informations (GPU)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UEjh8Rulquq",
        "outputId": "cfc8a19b-1498-4d8b-ea0e-52d892a51bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 23 15:32:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtS3fRhb5x6"
      },
      "source": [
        "# **2. Importation of librairies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS3XuLGyb5x_",
        "outputId": "bf9ac219-8a33-4444-af5e-37561907d717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.9.2\n",
            "Keras version: 2.9.0\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6HqNeyYKraU"
      },
      "source": [
        "#**3. Connexion à Google Colab pour acceder aux bases de données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXAc626acFRF",
        "outputId": "e2836482-8e81-4b62-c80c-50d478d6aef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-BpaZnLDmn"
      },
      "source": [
        "#**4. Cretate the labels file \"classes.txt\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "70eR5xy2nNZP"
      },
      "outputs": [],
      "source": [
        "!printf '%s\\n' 'fire' 'no_fire' 'start_fire'> classes.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyXXoZphLN1-"
      },
      "source": [
        "#**5. Training parameters and selectioon of Pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3cIzhz5iNn7F"
      },
      "outputs": [],
      "source": [
        "# Fix random seed \n",
        "tf.keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HwKf5hQLnUPi"
      },
      "outputs": [],
      "source": [
        "nb_classes = 3\n",
        "nbr_batch_size=64 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
        "dataset_path = \"gdrive/MyDrive/Challenge1\"\n",
        "input_dim=224 #@param [224,299] {type:\"raw\"}  \n",
        "dataset_name='db1' #@param [\"db1\",\"db2\"]\n",
        "dataset_path = os.path.join(dataset_path,dataset_name)\n",
        "classes_path = \"classes.txt\"\n",
        "csv_path = 'result.csv'\n",
        "epochs = 30 #@ param {type:\"slider\", min:5, max:100, step:5}\n",
        "\n",
        "result_path='results/'\n",
        "log_path='logs'\n",
        "\n",
        "classifier = \"Xception\" #@param [\"ResNet50\",\"VGG19\",\"Xception\",\"MobileNet\",\"DenseNet169\"] {type:\"string\"}\n",
        "result_path = 'results/'+classifier\n",
        "log={\n",
        "    'epochs':epochs,\n",
        "    'batch_size':nbr_batch_size,\n",
        "    'val_loss':-1,\n",
        "    'val_acc':-1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "94acb9Z0lc3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d086ef-354d-4a82-bd93-b7a0aaa89e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive/MyDrive/Challenge1/db1\n"
          ]
        }
      ],
      "source": [
        "print(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SBzh646b5yz"
      },
      "source": [
        "# **6. Get the number of classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NZ55HVhkb5y3"
      },
      "outputs": [],
      "source": [
        "# Get the class names\n",
        "with open(classes_path, 'r') as f:\n",
        "    classes = f.readlines()\n",
        "    classes = list(map(lambda x: x.strip(), classes))\n",
        "num_classes = len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1SqSdQUDkL-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3ff46a-39fc-4cca-904a-041a3086dfdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTyWV0pQb5zD"
      },
      "source": [
        "# **8. Selection and configuration of the training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UoWLjGra8Ls9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1910b1-c77f-46d8-e51f-6bed8b98f6c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8577 files belonging to 3 classes.\n",
            "Using 6862 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdataset_path,                     # Path of the dataset\n",
        "\tvalidation_split=0.2,             # Data division : validation (20%), train (80%)\n",
        "\tsubset=\"training\",                # Selection of training data\n",
        "\tseed=42,                          # Initialization of random generator (for permutations)\n",
        "\timage_size=(input_dim,input_dim),    # Input size of images\n",
        "\tbatch_size=nbr_batch_size,        # Batch_size\n",
        "  label_mode=\"categorical\"     # Conversion to One-Hot format\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji2AfPd88PC-"
      },
      "source": [
        "#**9. Selection and configuration of the validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7Oruux4rRyDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ebc211-096e-43d5-d8e5-78c9e2af15b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8577 files belonging to 3 classes.\n",
            "Using 1715 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdataset_path,                     # Path of the dataset\n",
        "\tvalidation_split=0.2,             # Data division : validation (20%), train (80%)\n",
        "\tsubset=\"validation\",                # Selection of validation data\n",
        "\tseed=42,                          # Initialization of random generator (for permutations)\n",
        "\timage_size=(input_dim,input_dim),    # Input size of images\n",
        "\tbatch_size=nbr_batch_size,        # Batch_size\n",
        "  label_mode=\"categorical\"     # Conversion to One-Hot format\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi8oBrIJWa5s"
      },
      "source": [
        "# **10. Download the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_WCBo9Oyb5zc"
      },
      "outputs": [],
      "source": [
        "base_model = Xception(include_top = False, weights ='imagenet',input_shape = (input_dim,input_dim,3))\n",
        "model = base_model.output\n",
        "model = Flatten()(model)\n",
        "model = Dense(128,activation='relu')(model)\n",
        "model = Dropout(0.8)(model)\n",
        "model = Dense(64,activation = 'relu')(model)\n",
        "model = Dropout(0.4)(model)\n",
        "predictions = Dense(num_classes, activation = 'softmax')(model)\n",
        "model = Model(inputs=base_model.inputs, outputs=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CWnXEPb5zX"
      },
      "source": [
        "# **13. Model training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GPGAZ2Vab5zo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "b992119f-15b5-4b42-f1d2-d8126552d10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 27/108 [======>.......................] - ETA: 2:02 - loss: 1.1741 - accuracy: 0.4485"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f7f4855c79c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# pour permettre le ré-entrainement des couches\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# recompiler le modèle\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001,decay=1e-6)\n",
        "opt2 = keras.optimizers.Adam(lr=0.0001)\n",
        "opt3 = keras.optimizers.RMSprop(learning_rate = 0.0001,decay =1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt3,metrics=['accuracy'])  \n",
        "\n",
        "\n",
        "# Création du dossier pour sauvegrader le model\n",
        "if os.path.exists(result_path) == False:\n",
        "    os.makedirs(result_path)\n",
        "\n",
        "\n",
        "keras_callback = [EarlyStopping(monitor='val_loss',patience = 5, verbose = 2)]\n",
        "\n",
        "history=model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=math.ceil(len(train_ds)),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=math.ceil(len(val_ds)),\n",
        "    verbose=1,\n",
        "    callbacks = keras_callback\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVOg-VgI9YMB"
      },
      "source": [
        "#**14. Save your model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbAlAYpm9fg5"
      },
      "outputs": [],
      "source": [
        "model.save('xception2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_ljTXlMSIZ"
      },
      "source": [
        "#**15. Visualization of training/validation curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtIwdjee_KLk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvX9QXRCh1GJ"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\t'test_data/test',          # chemin vers le jeu de données\n",
        "\tseed=42,                    # Initialisation du générateur aléatoire (permutations)\n",
        "\timage_size=(input_dim,input_dim),       # Taille des images d'entrée\n",
        "\tbatch_size=nbr_batch_size,      # Taille du mini-batch\n",
        "  label_mode='categorical'    # Conversion au format One-Hot\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxHxT0GFiQK4"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(test_ds,  steps=len(test_ds),workers = 1)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]))\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oECfYKSp_MaQ"
      },
      "source": [
        "#**16. Test the model with a test image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcKZUDoWUq0P"
      },
      "outputs": [],
      "source": [
        "filename = \"https://www.ecologie.gouv.fr/sites/default/files/styles/standard/public/Feux.png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_JRsQoh_chG"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "classes = train_ds.class_names\n",
        "image_path =  \"fog.jpg\"\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "x = tf.keras.utils.img_to_array(img,data_format='channels_last')\n",
        "x = tf.keras.preprocessing.image.smart_resize(x, size=(input_dim,input_dim))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# predict\n",
        "pred = model.predict(x,batch_size=1)[0]\n",
        "\n",
        "for (pos,prob) in enumerate(pred):\n",
        "    class_name = classes[pos]\n",
        "    if (pos == np.argmax(pred)) :\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX \n",
        "        textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
        "        textX = (img.shape[1] - textsize[0]) / 2\n",
        "        textY = (img.shape[0] + textsize[1]) / 2\n",
        "        cv2.putText(img, class_name, (int(textX)-10, int(textY)), font, 2, (255,0,0), 6, cv2.LINE_AA)\n",
        "        plt.imshow(img)\n",
        "    print(\"Class Name : %s\" % (class_name), \"---\", \"Class Probability: %.2f%%\" % (prob*100))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "28c92afe8325fc0816b2f334f44f38e4b06e562e4c3a673584693ef65fd7d28f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}